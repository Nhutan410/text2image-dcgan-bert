{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "K4h05EGvNRG3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 0Ô∏è‚É£ T·∫£i v√† gi·∫£i n√©n Flickr8k\n",
        "# ===========================\n",
        "def download_flickr8k(dataset_dir=\"Flickr8k\"):\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    # Danh s√°ch c√°c URL c·∫ßn t·∫£i\n",
        "    urls = {\n",
        "        \"images\": \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\",\n",
        "        \"captions\": \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\"\n",
        "    }\n",
        "\n",
        "    for key, url in urls.items():\n",
        "        zip_path = os.path.join(dataset_dir, f\"{key}.zip\")\n",
        "        extract_path = os.path.join(dataset_dir, key)\n",
        "\n",
        "        if not os.path.exists(extract_path):\n",
        "            print(f\"üì• Downloading {key} dataset...\")\n",
        "            urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "            print(f\"üìÇ Extracting {key} dataset...\")\n",
        "            with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(dataset_dir)\n",
        "\n",
        "            os.remove(zip_path)  # X√≥a file ZIP sau khi gi·∫£i n√©n\n",
        "\n",
        "    print(\"‚úÖ Dataset downloaded & extracted!\")\n",
        "\n",
        "download_flickr8k()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhbwkVKcNW5M",
        "outputId": "17b17d0f-a919-4747-b397-7b64e9a3921d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading images dataset...\n",
            "üìÇ Extracting images dataset...\n",
            "üì• Downloading captions dataset...\n",
            "üìÇ Extracting captions dataset...\n",
            "‚úÖ Dataset downloaded & extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "captions_file = \"Flickr8k/Flickr8k.token.txt\"\n",
        "image_dir = \"Flickr8k/Flicker8k_Dataset\"  # Th∆∞ m·ª•c ch·ª©a ·∫£nh\n",
        "captions = {}\n",
        "text = []\n",
        "\n",
        "with open(captions_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        img_name = parts[0].split(\"#\")[0]\n",
        "\n",
        "        # N·∫øu c√≥ \".1\" ·ªü cu·ªëi file th√¨ lo·∫°i b·ªè\n",
        "        if img_name.endswith(\".1\"):\n",
        "            img_name = img_name[:-2]  # B·ªè k√Ω t·ª± \".1\" ·ªü cu·ªëi\n",
        "\n",
        "        # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: {img_name}\")  # C·∫£nh b√°o file b·ªã thi·∫øu\n",
        "            continue  # B·ªè qua file kh√¥ng t·ªìn t·∫°i\n",
        "\n",
        "        caption = parts[1].lower()\n",
        "        text.append(caption)\n",
        "\n",
        "        if img_name not in captions:\n",
        "            captions[img_name] = []\n",
        "        captions[img_name].append(caption)\n",
        "\n",
        "print(\"S·ªë l∆∞·ª£ng ·∫£nh h·ª£p l·ªá:\", len(captions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT77ZaWXApfq",
        "outputId": "d9dd51e2-eb49-4023-d04f-95b21211b672"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i: 2258277193_586949ec62.jpg\n",
            "S·ªë l∆∞·ª£ng ·∫£nh h·ª£p l·ªá: 8091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm8Sk4fe-Lol",
        "outputId": "e354abe6-081e-4ad4-f1c4-2dceabbd1664"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "captions['209605542_ca9cc52e7b.jpg']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNHPUOpQiEF6",
        "outputId": "ea1ca0af-73df-43e1-b9d6-c293e25a0719"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a climber wearing a red headband is pulling himself up some grey rocks high above some green foliage .',\n",
              " 'a man in a headband climbing a rock .',\n",
              " 'a man with a red headband climbing a rock cliff looming over greenery .',\n",
              " 'man climbing a sheet rock face .',\n",
              " 'man in red headband climbing a rock']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dnzvm_Q3i1ah",
        "outputId": "2976f000-7926-48b4-90db-f9c37e580663"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a child in a pink dress is climbing up a set of stairs in an entry way .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers, models\n",
        "\n",
        "# T·∫°o tokenizer d·∫°ng word-based\n",
        "tokenizer = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
        "\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "trainer = trainers.WordLevelTrainer(\n",
        "    vocab_size=10000,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"<pad>\", \"<unk>\"]\n",
        ")\n",
        "\n",
        "# Hu·∫•n luy·ªán tokenizer\n",
        "tokenizer.train_from_iterator(text, trainer)\n",
        "\n",
        "# L∆∞u tokenizer\n",
        "tokenizer.save(\"tokenizer.json\")\n",
        "\n",
        "# Load t·ª´ ƒëi·ªÉn t·ª´ tokenizer\n",
        "vocab = tokenizer.get_vocab()  # Tr√≠ch xu·∫•t t·ª´ ƒëi·ªÉn\n",
        "word_to_id = lambda word: vocab.get(word, vocab[\"<unk>\"])  # H√†m l·∫•y ID c·ªßa t·ª´"
      ],
      "metadata": {
        "id": "boJY-KNJiTzq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# Load tokenizer ƒë√£ train v√†o PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"tokenizer.json\",\n",
        "    unk_token=\"<unk>\", pad_token=\"<pad>\"\n",
        ")"
      ],
      "metadata": {
        "id": "EXCXXpN1jDJ2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"i go to school\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu80T3nAjG-5",
        "outputId": "b40ca597-d432-47aa-f3d2-ef6374c3e059"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1427, 526, 21, 750], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1Ô∏è‚É£ Load Flickr8k dataset\n",
        "# ===========================\n",
        "class Flickr8kDataset(Dataset):\n",
        "    def __init__(self, img_dir, captions, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load captions\n",
        "        self.captions = captions\n",
        "\n",
        "        self.img_names = list(self.captions.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        caption = np.random.choice(self.captions[img_name])  # Ch·ªçn caption ng·∫´u nhi√™n\n",
        "        encoded_caption = tokenizer(caption, padding=\"max_length\",\n",
        "                                    truncation=True, max_length=20, return_tensors=\"pt\")['input_ids'][0]\n",
        "        return {\n",
        "            'image': image,\n",
        "            'caption': encoded_caption\n",
        "        }"
      ],
      "metadata": {
        "id": "tfeziVvQN3lz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((8, 8)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "dataset = Flickr8kDataset(\n",
        "    img_dir=\"/content/Flickr8k/Flicker8k_Dataset\",\n",
        "    captions=captions,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "K7ays76xN9pF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(dataset))\n",
        "\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9FulO3pj9TR",
        "outputId": "e33e2ad0-e003-403d-dae1-9dbdd64c4767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[-0.0824, -0.3412, -0.2471, -0.2706, -0.3647, -0.4196, -0.2549,\n",
              "           -0.5294],\n",
              "          [-0.2863, -0.5137, -0.1451, -0.2078, -0.4118, -0.4431, -0.2157,\n",
              "           -0.5373],\n",
              "          [-0.0902, -0.1765, -0.1608, -0.2471, -0.3490, -0.3255, -0.1059,\n",
              "           -0.4667],\n",
              "          [ 0.4510,  0.1529, -0.0824, -0.2471, -0.2863, -0.3333, -0.0902,\n",
              "           -0.2235],\n",
              "          [ 0.2157, -0.1059, -0.1529, -0.2235, -0.2392, -0.2627, -0.2314,\n",
              "           -0.3490],\n",
              "          [-0.5843, -0.7333, -0.5373, -0.3412, -0.2706, -0.2078, -0.0667,\n",
              "           -0.3098],\n",
              "          [-0.2549, -0.4431, -0.4902, -0.4824, -0.6863, -0.5686, -0.3176,\n",
              "           -0.3333],\n",
              "          [ 0.3255, -0.0353, -0.3255, -0.2863,  0.0196, -0.4118, -0.5529,\n",
              "           -0.1216]],\n",
              " \n",
              "         [[-0.0353, -0.4275, -0.3490, -0.3882, -0.5373, -0.5373, -0.3333,\n",
              "           -0.5137],\n",
              "          [-0.3333, -0.5922, -0.3255, -0.3647, -0.4980, -0.4902, -0.2784,\n",
              "           -0.4824],\n",
              "          [-0.2627, -0.3098, -0.3961, -0.4431, -0.4745, -0.3961, -0.1294,\n",
              "           -0.4118],\n",
              "          [-0.0118, -0.1294, -0.3333, -0.4510, -0.4039, -0.4196, -0.1686,\n",
              "           -0.1843],\n",
              "          [-0.1529, -0.3882, -0.3725, -0.4431, -0.4588, -0.4667, -0.3882,\n",
              "           -0.4275],\n",
              "          [-0.6314, -0.7725, -0.6235, -0.5294, -0.4980, -0.4510, -0.2941,\n",
              "           -0.4667],\n",
              "          [-0.3490, -0.5059, -0.5529, -0.5529, -0.6235, -0.6706, -0.5137,\n",
              "           -0.4431],\n",
              "          [ 0.0353, -0.2078, -0.3961, -0.3255,  0.0510, -0.5373, -0.6078,\n",
              "            0.0275]],\n",
              " \n",
              "         [[-0.1843, -0.5843, -0.5294, -0.5922, -0.7333, -0.7020, -0.5608,\n",
              "           -0.7490],\n",
              "          [-0.5137, -0.7412, -0.5451, -0.5686, -0.6471, -0.6235, -0.5373,\n",
              "           -0.7333],\n",
              "          [-0.4667, -0.4588, -0.6157, -0.6549, -0.6392, -0.5216, -0.4118,\n",
              "           -0.6392],\n",
              "          [-0.1137, -0.1608, -0.5373, -0.6471, -0.5608, -0.5373, -0.3647,\n",
              "           -0.4431],\n",
              "          [-0.1686, -0.4039, -0.5451, -0.6235, -0.6549, -0.6549, -0.6157,\n",
              "           -0.6471],\n",
              "          [-0.6941, -0.8353, -0.7098, -0.7098, -0.7020, -0.6784, -0.6000,\n",
              "           -0.7020],\n",
              "          [-0.5451, -0.6235, -0.6471, -0.6863, -0.7647, -0.8275, -0.7098,\n",
              "           -0.5922],\n",
              "          [-0.3569, -0.4588, -0.5451, -0.4431, -0.0353, -0.6863, -0.6549,\n",
              "            0.1765]]]),\n",
              " 'caption': tensor([   2,   41,   19,    4,    2,   92,  175,  321,   66,    2,  199, 3060,\n",
              "            3,    0,    0,    0,    0,    0,    0,    0])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbXQU6RKjrXc",
        "outputId": "463ed1c1-1648-49d1-c728-657deb003c38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['caption'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bti1bRqSjtcI",
        "outputId": "eb99c24d-3b47-474b-b0db-d63f52f0f9f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2Ô∏è‚É£ Word Embeddings + LSTM\n",
        "# ===========================\n",
        "class embedding_text(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(embedding_text, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, captions):\n",
        "        embeds = self.embedding(captions)\n",
        "        _, (hidden, _) = self.lstm(embeds)\n",
        "        return hidden[-1]\n",
        "\n",
        "# ===========================\n",
        "# 3Ô∏è‚É£ DCGAN Model\n",
        "# ===========================\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, embed_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + embed_dim, 128 * 4 * 4),\n",
        "            #       latent_dim (64) + embed_dim (256)\n",
        "            # Input:(batch_size,320) - Output:(batch_size,512)\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            # Input:(batch_size,512) - Output:(batch_size,128,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            # Input:(batch_size,128,4,4) - Output:(batch_size,64, 8, 8)\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 3, stride=1, padding=1),\n",
        "            # Input:(batch_size,64, 8, 8) - Output:(batch_size, 3, 8, 8)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, caption_embed):\n",
        "        x = torch.cat((noise, caption_embed), dim=1)\n",
        "        #  (batch_size,64) + (batch_size,256) = (batch_size,320)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
        "            # Input:(batch_size,3,8,8) - Output:(batch_size,64,4,4)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64 ,128 ,3 , stride=2, padding=1),\n",
        "            # Input:(batch_size,64,4,4) - Output:(batch_size,128,2,2)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten()\n",
        "            # Input:(batch_size,128,2,2) - Output:(batch_size,512)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(512 + embed_dim, 1)\n",
        "        # Input:(batch_size,512) - Output:(batch_size,1)\n",
        "\n",
        "    def forward(self, img, caption_embed):\n",
        "        img_features = self.cnn(img)\n",
        "        x = torch.cat((img_features, caption_embed), dim=1)\n",
        "        #  (batch_size,512) + (batch_size,256) = (batch_size,768)\n",
        "        return torch.sigmoid(self.fc(x))\n"
      ],
      "metadata": {
        "id": "YL6B1MqPGOAt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAnykd8rQMBU",
        "outputId": "7dd3e441-261f-471a-ba28-80c37c959f86"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5167"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Model\n",
        "generator = Generator(64, 256).to(device)\n",
        "discriminator = Discriminator(256).to(device)\n",
        "embedding_text = embedding_text(len(tokenizer), 256, 256).to(device)\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "2FoN_8oYkcig"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkyUvuChkekS",
        "outputId": "dfd4b3ff-dd1c-4cfb-e4bc-37fa800105bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "embedding_text(\n",
              "  (embedding): Embedding(5167, 256)\n",
              "  (lstm): LSTM(256, 256, batch_first=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtmLRlbdkgNI",
        "outputId": "d19e29f6-503e-4e8b-808d-1ae07ea12674"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=320, out_features=2048, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Unflatten(dim=1, unflattened_size=(128, 4, 4))\n",
              "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz4EN11kklTf",
        "outputId": "fe204596-ef9b-45a2-8481-728bc460ce32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (4): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "batch_sample = next(iter(dataloader))\n",
        "\n",
        "batch_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqkwMfaukwRB",
        "outputId": "a877a47c-cbfe-4647-b632-5afc2daf7e63"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[[ 0.4902,  0.6235,  0.6941,  ...,  0.5843,  0.4745,  0.4431],\n",
              "           [ 0.4980,  0.6000,  0.6627,  ...,  0.5294,  0.5137,  0.4824],\n",
              "           [ 0.3961,  0.2471,  0.5451,  ...,  0.7255,  0.7255,  0.6941],\n",
              "           ...,\n",
              "           [-0.9294, -0.8902, -0.1843,  ...,  0.0510,  0.1451,  0.1294],\n",
              "           [-0.9059, -0.9294, -0.6157,  ..., -0.4745,  0.1059,  0.0667],\n",
              "           [-0.6157, -0.4980, -0.6471,  ..., -0.2078,  0.2000,  0.0745]],\n",
              " \n",
              "          [[ 0.8431,  0.9059,  0.9373,  ...,  0.9137,  0.8588,  0.8118],\n",
              "           [ 0.8275,  0.8824,  0.9059,  ...,  0.8510,  0.8196,  0.7804],\n",
              "           [ 0.6392,  0.4353,  0.6863,  ...,  0.8196,  0.8118,  0.7804],\n",
              "           ...,\n",
              "           [-0.8745, -0.8510, -0.2471,  ...,  0.0039,  0.1373,  0.1216],\n",
              "           [-0.9216, -0.9059, -0.6000,  ..., -0.4745,  0.1137,  0.0667],\n",
              "           [-0.8431, -0.5765, -0.6471,  ..., -0.2706,  0.1529,  0.0588]],\n",
              " \n",
              "          [[ 0.9608,  0.9765,  0.9843,  ...,  0.9922,  0.9922,  0.9922],\n",
              "           [ 0.9294,  0.9529,  0.9608,  ...,  0.9765,  0.9608,  0.9451],\n",
              "           [ 0.7098,  0.4588,  0.7020,  ...,  0.7882,  0.7647,  0.7490],\n",
              "           ...,\n",
              "           [-0.9059, -0.8824, -0.3412,  ..., -0.0353,  0.1373,  0.1373],\n",
              "           [-0.9529, -0.9373, -0.6471,  ..., -0.5216,  0.1137,  0.0745],\n",
              "           [-0.8510, -0.6157, -0.7020,  ..., -0.3569,  0.0902,  0.0431]]],\n",
              " \n",
              " \n",
              "         [[[-0.1216, -0.1451, -0.0588,  ..., -0.3098, -0.3098, -0.3098],\n",
              "           [-0.0353, -0.0745, -0.1843,  ..., -0.0667, -0.2078, -0.1608],\n",
              "           [ 0.3569,  0.3569,  0.1686,  ...,  0.2706,  0.2392,  0.2471],\n",
              "           ...,\n",
              "           [-0.2392, -0.1294,  0.0510,  ...,  0.3804,  0.3412,  0.3176],\n",
              "           [ 0.0667,  0.0980,  0.2392,  ...,  0.3255,  0.1922,  0.0980],\n",
              "           [ 0.3961,  0.3804,  0.3804,  ...,  0.3882,  0.3490,  0.3569]],\n",
              " \n",
              "          [[-0.0980, -0.1137, -0.0275,  ..., -0.2863, -0.2941, -0.3020],\n",
              "           [-0.0431, -0.0824, -0.1922,  ..., -0.0588, -0.2078, -0.1608],\n",
              "           [ 0.2941,  0.2941,  0.0745,  ...,  0.2157,  0.1843,  0.1843],\n",
              "           ...,\n",
              "           [-0.2235, -0.1373, -0.0118,  ...,  0.3098,  0.2784,  0.2549],\n",
              "           [ 0.0118,  0.0510,  0.1765,  ...,  0.2471,  0.1373,  0.0431],\n",
              "           [ 0.3333,  0.3098,  0.3176,  ...,  0.3255,  0.2863,  0.2941]],\n",
              " \n",
              "          [[-0.0588, -0.0824,  0.0118,  ..., -0.2627, -0.2706, -0.3020],\n",
              "           [-0.0588, -0.1137, -0.2392,  ..., -0.0510, -0.2235, -0.1922],\n",
              "           [ 0.2000,  0.2000, -0.0118,  ...,  0.1373,  0.0902,  0.0902],\n",
              "           ...,\n",
              "           [-0.2392, -0.1608, -0.0980,  ...,  0.2000,  0.1765,  0.1529],\n",
              "           [-0.0667, -0.0275,  0.0745,  ...,  0.1373,  0.0510, -0.0431],\n",
              "           [ 0.2314,  0.2157,  0.2078,  ...,  0.2157,  0.1843,  0.1922]]],\n",
              " \n",
              " \n",
              "         [[[-0.3961, -0.3098, -0.1451,  ..., -0.3804, -0.4667, -0.1294],\n",
              "           [-0.3333, -0.2784, -0.1765,  ..., -0.2078, -0.4745, -0.0667],\n",
              "           [-0.2706, -0.3255, -0.3882,  ..., -0.2157, -0.5529, -0.1451],\n",
              "           ...,\n",
              "           [ 0.0745, -0.0353, -0.4667,  ..., -0.3333, -0.7725, -0.3725],\n",
              "           [-0.4824, -0.5686, -0.6392,  ..., -0.6471, -0.8667, -0.5216],\n",
              "           [-0.5843, -0.5765, -0.6392,  ..., -0.8353, -0.9137, -0.6941]],\n",
              " \n",
              "          [[-0.3490, -0.2627, -0.1137,  ..., -0.3725, -0.4667, -0.1216],\n",
              "           [-0.2941, -0.2314, -0.1529,  ..., -0.2000, -0.4745, -0.0667],\n",
              "           [-0.2314, -0.2235, -0.2471,  ..., -0.2078, -0.5451, -0.1451],\n",
              "           ...,\n",
              "           [ 0.1216, -0.0118, -0.5059,  ..., -0.3490, -0.7725, -0.3725],\n",
              "           [-0.5216, -0.6000, -0.7098,  ..., -0.7098, -0.8745, -0.5529],\n",
              "           [-0.5922, -0.5922, -0.6706,  ..., -0.8588, -0.9216, -0.7333]],\n",
              " \n",
              "          [[-0.3725, -0.2941, -0.1216,  ..., -0.3882, -0.4824, -0.1373],\n",
              "           [-0.3176, -0.2627, -0.1843,  ..., -0.2157, -0.4902, -0.0824],\n",
              "           [-0.2471, -0.1608, -0.1294,  ..., -0.2314, -0.5765, -0.1686],\n",
              "           ...,\n",
              "           [ 0.1373, -0.0196, -0.5608,  ..., -0.3961, -0.8039, -0.4118],\n",
              "           [-0.6235, -0.7020, -0.7882,  ..., -0.7725, -0.8980, -0.6314],\n",
              "           [-0.8588, -0.8588, -0.8745,  ..., -0.9216, -0.9451, -0.8510]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[ 0.7333,  0.8588,  0.6549,  ...,  0.9137,  0.8902,  0.7255],\n",
              "           [ 0.6941,  0.7725,  0.4745,  ...,  0.8353,  0.8196,  0.7647],\n",
              "           [ 0.3255,  0.5059,  0.4118,  ...,  0.6314,  0.4745,  0.4431],\n",
              "           ...,\n",
              "           [-0.2392,  0.3569,  0.7098,  ...,  0.7412,  0.7725,  0.3490],\n",
              "           [-0.4118, -0.0196,  0.1922,  ...,  0.3098,  0.6627,  0.2784],\n",
              "           [-0.4510, -0.2627, -0.1608,  ..., -0.1216,  0.0196, -0.1922]],\n",
              " \n",
              "          [[ 0.7255,  0.8588,  0.5765,  ...,  0.9137,  0.8902,  0.7020],\n",
              "           [ 0.6941,  0.7647,  0.3333,  ...,  0.8196,  0.8196,  0.7490],\n",
              "           [ 0.3255,  0.4588,  0.3020,  ...,  0.6078,  0.4902,  0.4588],\n",
              "           ...,\n",
              "           [-0.1843,  0.3020,  0.5843,  ...,  0.6471,  0.6784,  0.3020],\n",
              "           [-0.3490, -0.0431,  0.1137,  ...,  0.2078,  0.5137,  0.1608],\n",
              "           [-0.3882, -0.2078, -0.1373,  ..., -0.1529, -0.0353, -0.2314]],\n",
              " \n",
              "          [[ 0.7412,  0.8588,  0.5216,  ...,  0.9294,  0.9059,  0.6784],\n",
              "           [ 0.6941,  0.7569,  0.2549,  ...,  0.8196,  0.8039,  0.7255],\n",
              "           [ 0.2392,  0.3961,  0.2000,  ...,  0.5922,  0.4118,  0.4510],\n",
              "           ...,\n",
              "           [-0.6549, -0.4902, -0.5608,  ..., -0.2392, -0.1922, -0.6314],\n",
              "           [-0.8353, -0.8275, -0.6471,  ..., -0.5294, -0.8353, -0.8510],\n",
              "           [-0.9137, -0.8510, -0.7725,  ..., -0.7020, -0.8275, -0.8667]]],\n",
              " \n",
              " \n",
              "         [[[-0.4510, -0.2941, -0.2471,  ..., -0.3882, -0.2314, -0.0431],\n",
              "           [-0.4118, -0.5137, -0.3098,  ..., -0.4824, -0.2627, -0.3725],\n",
              "           [-0.2706, -0.4118,  0.0196,  ..., -0.4588, -0.2235, -0.4745],\n",
              "           ...,\n",
              "           [-0.1529,  0.0196, -0.0353,  ..., -0.0980,  0.1294,  0.1451],\n",
              "           [-0.5686, -0.1765,  0.1137,  ..., -0.0039,  0.1922,  0.4510],\n",
              "           [-0.7020, -0.3961, -0.3020,  ..., -0.1765, -0.1843,  0.3098]],\n",
              " \n",
              "          [[-0.4118, -0.2706, -0.2941,  ..., -0.3882, -0.1686,  0.0667],\n",
              "           [-0.3961, -0.4588, -0.3490,  ..., -0.5059, -0.2549, -0.2863],\n",
              "           [-0.2549, -0.4275, -0.2000,  ..., -0.4980, -0.2000, -0.3961],\n",
              "           ...,\n",
              "           [-0.2078,  0.0196,  0.0039,  ..., -0.1765,  0.1059,  0.0902],\n",
              "           [-0.7725, -0.1451,  0.1608,  ..., -0.0667,  0.1843,  0.4275],\n",
              "           [-0.9137, -0.3725, -0.2549,  ..., -0.1059, -0.1608,  0.1294]],\n",
              " \n",
              "          [[-0.6314, -0.4745, -0.3725,  ..., -0.4745, -0.3176, -0.4980],\n",
              "           [-0.5294, -0.6078, -0.4824,  ..., -0.5843, -0.4431, -0.6392],\n",
              "           [-0.4431, -0.5843, -0.3882,  ..., -0.6078, -0.3882, -0.6549],\n",
              "           ...,\n",
              "           [-0.2706,  0.0588,  0.2000,  ..., -0.3647, -0.1373, -0.2471],\n",
              "           [-0.8196, -0.0353,  0.2314,  ..., -0.2941,  0.0431,  0.2706],\n",
              "           [-0.9216, -0.3098, -0.2000,  ..., -0.0431, -0.2157, -0.1843]]],\n",
              " \n",
              " \n",
              "         [[[ 0.9294,  0.8588,  0.7804,  ...,  0.1765,  0.1765,  0.3333],\n",
              "           [ 0.7255,  0.5529,  0.4588,  ...,  0.0118,  0.3333,  0.3647],\n",
              "           [ 0.3882,  0.2549,  0.1451,  ..., -0.2941,  0.2549,  0.2314],\n",
              "           ...,\n",
              "           [-0.0196,  0.0824,  0.1686,  ..., -0.0196, -0.0824, -0.0118],\n",
              "           [-0.2157, -0.1843, -0.1059,  ..., -0.1294, -0.1294, -0.1216],\n",
              "           [-0.5608, -0.4902, -0.3176,  ..., -0.2078, -0.2157, -0.2706]],\n",
              " \n",
              "          [[ 0.9059,  0.8353,  0.7569,  ...,  0.1843,  0.1765,  0.3333],\n",
              "           [ 0.7255,  0.5686,  0.4745,  ...,  0.0275,  0.3412,  0.3647],\n",
              "           [ 0.4353,  0.3255,  0.2235,  ..., -0.3098,  0.2627,  0.2392],\n",
              "           ...,\n",
              "           [-0.0667,  0.0667,  0.1843,  ..., -0.0039, -0.0745, -0.0039],\n",
              "           [-0.4275, -0.3882, -0.3255,  ..., -0.2706, -0.2627, -0.2392],\n",
              "           [-0.6235, -0.6157, -0.5686,  ..., -0.5529, -0.5373, -0.5529]],\n",
              " \n",
              "          [[ 0.8902,  0.8353,  0.7569,  ...,  0.2157,  0.2157,  0.3490],\n",
              "           [ 0.7255,  0.6000,  0.5059,  ...,  0.0510,  0.3569,  0.3725],\n",
              "           [ 0.4667,  0.3804,  0.2784,  ..., -0.3490,  0.2706,  0.2706],\n",
              "           ...,\n",
              "           [-0.1843, -0.0588,  0.0588,  ..., -0.0588, -0.1137, -0.0118],\n",
              "           [-0.7176, -0.7020, -0.6627,  ..., -0.6314, -0.6078, -0.5843],\n",
              "           [-0.9137, -0.8902, -0.8431,  ..., -0.8039, -0.7647, -0.7647]]]]),\n",
              " 'caption': tensor([[   5,  112,   17,  ...,    0,    0,    0],\n",
              "         [   2,    9,  555,  ...,    0,    0,    0],\n",
              "         [   2,   11,    4,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [   2,   27,   16,  ...,    0,    0,    0],\n",
              "         [  16,  427,   20,  ...,    0,    0,    0],\n",
              "         [   1, 1545,    4,  ...,    0,    0,    0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sample['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRoBjbvtkS-P",
        "outputId": "b87f8959-a162-4851-9d2e-4b796796ff47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sample['caption'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOz3u7hNlJ_Y",
        "outputId": "18b9911b-865c-4489-d532-2ad552e5ec8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caption_embeddings = embedding_text(batch_sample['caption'].to(device))\n",
        "\n",
        "caption_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjCgzQvNk-Po",
        "outputId": "513e3383-faaf-422c-dc89-9fb8fcc0e755"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = torch.randn(batch_sample['image'].size(0), 64, device=device)\n",
        "fake_images = generator(noise, caption_embeddings)\n",
        "\n",
        "fake_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5LwWBCvUW1j",
        "outputId": "17ab7a00-14c2-4742-eb50-ed3483bea4a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch in dataloader:\n",
        "        # load tensor images\n",
        "        images = batch['image'].to(device)\n",
        "        # load one-hot vector tokenizer\n",
        "        captions = batch['caption'].to(device)\n",
        "\n",
        "        caption_embeddings = embedding_text(captions)\n",
        "        #  (batch_size, 256)\n",
        "        noise = torch.randn(images.size(0), 64, device=device)\n",
        "        #  (batch_size, 64)\n",
        "\n",
        "        fake_images = generator(noise, caption_embeddings)\n",
        "        #  (batch_size, 3, 8, 8)\n",
        "        real_labels = torch.ones(images.size(0), 1, device=device)\n",
        "        #  (batch_size, 1)\n",
        "        fake_labels = torch.zeros(images.size(0), 1, device=device)\n",
        "        #  (batch_size, 1)\n",
        "\n",
        "        real_loss = criterion(discriminator(images, caption_embeddings), real_labels)\n",
        "        fake_loss = criterion(discriminator(fake_images.detach(), caption_embeddings), fake_labels)\n",
        "        '''    Detaches fake_images from the computation graph so that gradients\n",
        "        do not flow back to the generator during Discriminator training.     '''\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        #  retain_graph=True\n",
        "        optimizer_D.step()\n",
        "\n",
        "        g_loss = criterion(discriminator(fake_images, caption_embeddings), real_labels)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/5], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uJGjk1DiqQc",
        "outputId": "eddea61b-1292-429d-d81e-e145b07d6fc1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], D Loss: 1.3159996271133423, G Loss: 0.9297963380813599\n",
            "Epoch [2/5], D Loss: 1.241675853729248, G Loss: 0.8472822904586792\n",
            "Epoch [3/5], D Loss: 1.1022919416427612, G Loss: 1.2151697874069214\n",
            "Epoch [4/5], D Loss: 1.2709544897079468, G Loss: 0.8273096680641174\n",
            "Epoch [5/5], D Loss: 1.3431909084320068, G Loss: 0.8363375067710876\n"
          ]
        }
      ]
    }
  ]
}